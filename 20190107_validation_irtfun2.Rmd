---
title: "MML-EM_validation"
author: "T.SHIBUYA"
date: "2019/1/8"
output: md_document
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE, comment = NA)
library(tidyverse)
library(magrittr)
library(irtfun2)
library(lazy.irtx)
```

# プログラム推定値の妥当性検証

## 妥当性検証がなぜ必要か

　IRTに限らず数値計算を実行するプログラムで重要なことは，得られている結果が本当に正しいのかどうかです。

　ソフトウェア単体であれば，収束しているかどうかや適合度，周辺対数尤度の数値の変化などを確認することで，推定プログラムがうまくいっているかどうかを知ることができます。

　しかし，より複雑なプログラムになればそれだけでは不十分であり，一見収束していても，正しい推定値が得られていないことがあります。それはプログラムの数値計算等の本質的な部分ではなく，イテレーションの範囲を指定することが間違っていたり，符号が逆だったりなど，細部の設定によるものだったりします。大抵，数値計算部分でうまくプログラムが組めていない場合，収束しなかったり，明らかにおかしな値を取るため，すぐわかります。

## 使用するプログラムについて

　`irtfun2`パッケージの`estip`の妥当性検証のためには`kazy.irt`とEasy Estimationを使うことにします。本当であれば商用のプログラムを使いたいところですが，無料でできる範囲でやってみます。

## シミュレーションデータの生成。

　擬似的に発生させた$\theta$と識別力，困難度から２PLMにしたがって項目反応データを生成します。パラメタから反応確率を計算し，その確率と一様乱数を比較する，単純な棄却法です。`irtfun2`の`sim_gen`にも同様の方法が用いられています。

　しかし，今回は多母集団モデルに基づく推定を実行するため，少し複雑です。はじめに母集団のパラメタ(正規分布の平均とSD)を指定しておきます。

　今回想定するテストデザインは尺度化テストデザインと呼ばれるものです。通常の共通項目デザインとは異なり，全ての集団間で共通の項目を一部に含むデザインです。


```{r data}
# sample data generating


# IRT 2 PLM response probability
ptheta2 <- function(theta, a, b){
  D <- 1.702
  1/(1+exp(-D*a*(theta-b)))
}

# item response probability
resfunc2 <- function(prob){
  prob <- matrix(prob, ncol = 1)
  subfunc <- function(prob){
    if(prob < runif(1)) res <- 0
    else res <- 1
    return(res)
  }
  res <- apply(prob, 1, subfunc)
  return(res)
}

# theta parameter
thetaMS <- matrix(c(-0.8,1.0,
                    -0.4,1.0,
                     0.0,1.0,
                     0.4,1.0,
                     0.8,1.0),
                  ncol = 2, byrow = T)

# grade ID
gradeID <- c("A","B","C","D","E")

# true item parameter matrix
true_para <- matrix(nrow = 30*7/3, ncol = 2)


jj <- 1

set.seed(0204)
# grade item parameter
for(g in 1:5){
  
  if(g == 1){ # 第一学年だけ，項目数が異なる（基準となるので）
    # item parameters(exept scaling test item)
    for(j in 1:(30*2/3)){
      true_para[jj,1] <- rlnorm(1, -0.5, 0.3)
      true_para[jj,2] <- rnorm(1, thetaMS[g,1], thetaMS[g,2])
      jj <- jj + 1 # 挿入行数カウント
    }
  } else {
    for(j in 1:(30*1/3)){
      true_para[jj,1] <- rlnorm(1, -0.5, 0.3)
      true_para[jj,2] <- rnorm(1, thetaMS[g,1], thetaMS[g,2])
      jj <- jj + 1 # 挿入行数カウント
    }
  }
}


# scaling test item parameter
for(g in 1:(30*1/3)){
  true_para[jj,1] <- rlnorm(1, -1, 0.5)
  true_para[jj,2] <- runif(1, -3, 3)
  jj <- jj + 1
}
true_para <- data.frame(V3 = true_para[,1], V4 = true_para[,2])

rm(jj)



al <- c("a","b","c","d","e","f","st")
c <- 2
for(i in c("a","b","c","d","e")){
  
  num <- formatC(c(1:(30*1/3)), width = 3, flag = 0)
  
  if(i =="a"){
    itemn1 <- apply(matrix(i, ncol = 1), 1, paste0, num)
    itemn2 <- apply(matrix(al[c], ncol = 1), 1, paste0, num)
    itemn3 <- apply(matrix(al[7], ncol = 1), 1, paste0, num)
    itemID <- rbind(itemn1,itemn2,itemn3)
  }  
  
  if(i !="a") {
    itemn1 <- apply(matrix(i, ncol = 1), 1, paste0, num)
    itemn2 <- apply(matrix(al[c], ncol = 1), 1, paste0, num)
    itemn3 <- apply(matrix(al[7], ncol = 1), 1, paste0, num)
    itemn <- rbind(itemn1,itemn2,itemn3)
    itemID <- cbind(itemID,itemn)
    rm(itemn1,itemn2,itemn3,itemn,num)
  }
  c <- c + 1
} # end of i

rm(al,c)


for(g in 1:5){
  if( g == 1){
    gradeitem <- c(seq.int(1,length.out = 30*2/3), seq.int(30*2 + 1, length.out = 30*1/3))
  } else {
    gradeitem <- c(seq.int(g*30*1/3+1,length.out = 30*2/3), seq.int(30*2 + 1, length.out = 30*1/3))
  }
  
  a <-  true_para[gradeitem, 1]
  b <-  true_para[gradeitem, 2]
  
  # ability parameter
  theta <- rnorm(1000, thetaMS[g,1], thetaMS[g,2])
  
  # generate response patterns exept scaling test item
  resp <- theta %>% 
    matrix(ncol = 1) %>% 
    apply(1,ptheta2, a = a, b = b) %>% 
    apply(2,resfunc2) %>% 
    t() %>% 
    as.data.frame() 
  
  colnames(resp) <- itemID[,g]
  
  grade <- rep(g, 1000) %>% as.numeric() # グループIDはnumeric型であること。
  
  ID <- apply(matrix(gradeID[g], ncol = 1), 1, paste0,
              formatC(c(1:1000), width = 5, flag = 0)) %>% 
    as.character()
  
  resp <- cbind(ID, grade, resp)
  
  if(g == 1) {
    RESP <- resp
  } else {
    # combine response data for concurrent calibration
    RESP %<>% dplyr::full_join(resp) %>% suppressWarnings() %>% suppressMessages()
  }
  
} # end of one grade 
rm(a,b,g,grade,gradeID,gradeitem,i,ID,j,theta,itemID,resp)

RESP2 <- RESP
RESP2$grade <- matrix(c(3,2,1,4,5)) %>% apply(1, rep.int, times = 1000) %>% as.vector()

# Output response data for Easy Estimation
write.table(RESP2, file="vald_data.dat", quote = F, sep = "", col.names = F, row.names = F, na="N")

true_para <- data.frame(a=true_para$V3, b=true_para$V4)


RESP %>% head(10) %>% knitr::kable(format = "markdown")

```

### 学年ごとに素点のヒストグラムを描画

　こんな感じのデータを作りました。

```{r}
hist_dat <- data.frame(grade=RESP$grade %>% as.character())
hist_dat$RawScore = rowSums(RESP[,c(-1,-2)], na.rm = T)
hist_dat %>% ggplot(aes(x=RawScore, fill=grade, colour=grade)) + geom_histogram(binwidth = 1) + facet_grid(grade~.)
```


##  推定＆結果

　先ほど作った項目反応データから項目パラメタを推定してみます。Easy EstimationはRからは実行できないので，あらかじめ推定して得られたパラメタファイルを読み込んでおきます。

```{r, cache=TRUE}
#irtfun2
res_irtfun2 <- irtfun2::estip(RESP2, ng = 5, gc = 2, fc = 3, min = -6, max = 6, thdist = "empirical", print = 0)
#lazy.irtx
res_lazy <- lazy.irt::uIRT(RESP2, idvar = "ID",groupvar = "grade" ,type = rep("B2",ncol(RESP2)-2), 
                           baseform = 1, estmu = 1, estsigma = 1, npoint = 31, print = 0, 
                           eps = 1e-4, epsd = 1e-5, thmin = -6, thmax = 6)
# Easy Estimation
res_easy <- read.csv("vald_dataPara.csv", skip = 1, header = F)
```

　`irtfun2`の thdist = "empirical" というオプションは，$\theta$の事前分布に，Eステップの計算から得られた多項分布を使用するためです。Easy Estimationはこの設定で動いていますが，lazy.irtは正規分布を使用しているようです。

###  真値　　

　パラメタの真値はこんな感じです

```{r}
true_para %>% knitr::kable(format = "markdown")
```

##  パラメタごとの比較

* 真値: true  
* irtfun2: irtfun2  
* lazy.irtx: lazy  
* Easy Estimation: Easy

で表記。 

```{r, include=TRUE}
comp_a <- data.frame(Item=res_irtfun2$para$Item, true=true_para$a, irtfun2=res_irtfun2$para$a, lazy=res_lazy$param$p1, Easy=res_easy$V3)
comp_b <- data.frame(Item=res_irtfun2$para$Item, true=true_para$b, irtfun2=res_irtfun2$para$b, lazy=res_lazy$param$p2, Easy=res_easy$V4)

label_grade <- c(rep("G1",20),rep("G2",10),rep("st",10),rep("G3",10),rep("G4",10),rep("G5",10))

comp_a$grade <- label_grade
comp_b$grade <- label_grade

Item <- res_irtfun2$para$Item %>% as.character()
```


###  識別力
```{r, fig.align="center", fig.height=10}
comp_a %>% knitr::kable(format = "markdown")
#write.csv(comp_a, "comp_a_table.csv", quote = F, row.names = F)

comp_a_d <- comp_a %>%  tidyr::gather(key=method, value=a, -Item, -grade)
comp_a_d$method %<>% factor(levels = c("true", "irtfun2", "lazy", "Easy"))

# ggplot
comp_a_d %>% ggplot(aes(x=a, y=Item, fill=grade, colour=grade))+
  geom_point()+
  facet_grid(.~method)
# ggsave("comp_a.png")
```

###  困難度
```{r, fig.align="center", fig.height=10}
comp_b %>% knitr::kable(format = "markdown")
# write.csv(comp_b, "comp_b_table.csv", quote = F, row.names = F)

comp_b_d <- comp_b %>%  tidyr::gather(key=method, value=a, -Item, -grade)
comp_b_d$method %<>% factor(levels = c("true", "irtfun2", "lazy", "Easy"))

comp_b_d %>% ggplot(aes(x=a, y=Item, fill=grade, colour=grade))+
  geom_point()+
  facet_grid(.~method)
# ggsave("comp_b.png")
```

##  Easy との比較  
```{r}
adiff <- res_easy$V3 - res_irtfun2$para$a
bdiff <- res_easy$V4 - res_irtfun2$para$b

diff_i_e <- data.frame(Item = Item, label = label_grade, a = adiff, b = bdiff)
diff_i_e %>% knitr::kable(format = "markdown")

diff_i_e %>% tidyr::gather(key = type_of_para, value = para, -Item, -label) %>% 
  ggplot(aes(x = para, y = Item, colour = label))+
  geom_point()+
  facet_wrap(.~type_of_para)+
  theme(legend.position = 'none')
```

　識別力は全体での差はほとんどないと言って良いですね。困難度は上のレベルの項目ではちょっと大きくズレているようですが，いずれも0.02程度ですし，問題ないでしょう。aしかし，001の項目はなぜか大きくズレていますね。

##  lazy との比較  
```{r}
adiff <- res_lazy$param$p1 - res_irtfun2$para$a
bdiff <- res_lazy$param$p2 - res_irtfun2$para$b

diff_i_l <- data.frame(Item = Item, label = label_grade, a = adiff, b = bdiff)
diff_i_l %>% knitr::kable(format = "markdown")

diff_i_l %>% tidyr::gather(key = type_of_para, value = para, -Item, -label) %>% 
  ggplot(aes(x = para, y = Item, colour = label))+
  geom_point()+
  facet_wrap(.~type_of_para)+
  theme(legend.position = 'none')
```

　困難度で系統的なズレが生じていますが，おそらく尺度の原点の設定の問題でしょう。lazy.irtの多母集団推定の基準設定にバグがあるようです。

##  lazyとEasyの比較  
```{r}
adiff <- res_easy$V3 - res_lazy$param$p1 
bdiff <- res_easy$V4 - res_lazy$param$p2 

diff_l_e <- data.frame(Item = Item, label = label_grade, a = adiff, b = bdiff)
diff_l_e %>% knitr::kable(format = "markdown")

diff_l_e %>% tidyr::gather(key = type_of_para, value = para, -Item, -label) %>% 
  ggplot(aes(x = para, y = Item, colour = label))+
  geom_point()+
  facet_wrap(.~type_of_para)+
  theme(legend.position = 'none')
```

　irtfun2の推定結果と同様に，困難度に系統的なズレがあるものの，識別力の推定結果はほとんど一致しています。


##  trueとirtfun2の比較

```{r}
adiff <- true_para$a - res_irtfun2$para$a
bdiff <- true_para$b - res_irtfun2$para$b

diff_i_t <- data.frame(Item = Item, label = label_grade, a = adiff, b = bdiff)
diff_i_t %>% knitr::kable(format = "markdown")

diff_i_t %>% tidyr::gather(key = type_of_para, value = para, -Item, -label) %>% 
  ggplot(aes(x = para, y = Item, colour = label))+
  geom_point()+
  facet_wrap(.~type_of_para)+
  theme(legend.position = 'none')
```

##  true とEasyの比較  
```{r}
adiff <- true_para$a - res_easy$V3
bdiff <- true_para$b - res_easy$V4

diff_e_t <- data.frame(Item = Item, label = label_grade, a = adiff, b = bdiff)
diff_e_t %>% knitr::kable(format = "markdown")

diff_e_t %>% tidyr::gather(key = type_of_para, value = para, -Item, -label) %>% 
  ggplot(aes(x = para, y = Item, colour = label))+
  geom_point()+
  facet_wrap(.~type_of_para)+
  theme(legend.position = 'none')
```


##  true とlazyの比較  
```{r}
adiff <- true_para$a - res_lazy$param$p1
bdiff <- true_para$b - res_lazy$param$p2

diff_l_t <- data.frame(Item = Item, label = label_grade, a = adiff, b = bdiff)
diff_l_t %>% knitr::kable(format = "markdown")

diff_l_t %>% tidyr::gather(key = type_of_para, value = para, -Item, -label) %>% 
  ggplot(aes(x = para, y = Item, colour = label))+
  geom_point()+
  facet_wrap(.~type_of_para)+
  theme(legend.position = 'none')
```

　G2からG4あたりまでは推定精度がかなりいいのですが，シミュレーションデータでもG1やstのような分布の端の方に位置するような項目は推定精度がかなり悪いです。個人的な研究の範囲だと，全学年共通項目は対応づけの観点からかなりきつい制約がかかって推定されることがわかっているので，それが原因でこんなに推定値がズレているのでしょう。

<!-- ##  母集団分布の比較（推定値のみ）　　 -->
<!-- ###  MML-EMで推定された母集団平均＆標準偏差 -->

<!-- |学年|平均|標準偏差| -->
<!-- |----|----|--------| -->
<!-- |G1|0|1| -->
<!-- |G2|0.4329271|1.0998473| -->
<!-- |G3|0.8267747|0.9683944| -->
<!-- |G4|1.3176517|0.8820991| -->
<!-- |G5|1.8727051|0.7246097| -->


<!-- ### 真値として設定した母集団平均＆標準偏差 -->

<!-- |学年|平均|標準偏差| -->
<!-- |----|----|--------| -->
<!-- |G1|0|1| -->
<!-- |G2|0.4|0.9| -->
<!-- |G3|0.8|0.8| -->
<!-- |G4|1.2|0.7| -->
<!-- |G5|1.6|0.6| -->



<!-- ###  Easy Estimationで推定された母集団平均＆標準偏差 -->

<!-- |学年|平均|標準偏差| -->
<!-- |----|----|--------| -->
<!-- |G1|0.00000|1.00000| -->
<!-- |G2|0.43082|1.10222| -->
<!-- |G3|0.82613|0.97573| -->
<!-- |G4|1.32027|0.90939| -->
<!-- |G5|1.88322|0.75216| -->


<!-- ###  lazy.irtxで推定された母集団平均＆標準偏差 -->

<!-- |学年|平均|標準偏差| -->
<!-- |----|----|--------| -->
<!-- |G1|0|1| -->
<!-- |G2|0.4291024|1.0989962| -->
<!-- |G3|0.8195406|0.9685041| -->
<!-- |G4|1.3096390|0.8914594| -->
<!-- |G5|1.8712678|0.7441478| -->

<!-- 推定母集団分布も，myfuncの推定結果はEasy Estimationとlazy.irtxの推定結果と類似しており，推定プログラムは正常に機能していると言える。 -->
