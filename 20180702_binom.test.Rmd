---
title: "符号検定（二項検定）についての考察"
author: "T.Shibuya"
date: "2018年7月2日"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, warning = F)
library(class)
```

要は，ある二つのデータ（プレポスト）の差を取った時に，その変化に有意差があるかをみる検定です。より正しくは，2つのカテゴリに分類されたデータの比率が，想定される分布から有意に偏っているかの検定です（符号検定の場合は，ですが）。  

なお，二項検定の，カテゴリが2つで，どちらのカテゴリも同じ確率で生じるような検定を，符号検定といいます。  


石井さんの示してくれたデータの場合，irisの部位ごとに，分類結果の一致・不一致をみていました。この二項検定の場合，帰無仮説は「二つの分類結果が同じ確率分布に従う」，つまり「二つの分類結果に（有意な）差はない」というものになります。  

ふたつの分類結果が同じ確率分布に従っているとしたら，一致する度数（文書数，分類データ数）と不一致する度数も同じになるはずです。これを利用して検定を行います。  

pythonの二項検定用のモジュール（関数）は

`stats.binom_test(一致（不一致）度数，文書数，二項分布の確率)`

であり，Rのばあい

`binom.test( (一致（不一致）度数，文書数，二項分布の確率)`


です。以下，Rを使って，説明します。   


はじめにコイントスの例です。  
いかさまのないコインであれば，当然表と裏のでる確率は等しく，確率の総和は１になるため，表（裏）の出る確率は0.5です。  

いま，いかさまのコインを調べたいとします。このコインは100回投げると40回しか表が出ませんでした。果たしてこのコインはいかさまと呼べるでしょうか。  

仮に二つのコインが全く同じであった場合，コインの表裏のでる確率は同じになるはずです。これが同じ確率分布にしたがうと言うことです。  

 そして統計的仮説検定では，同じ確率分布から得られた事象であったと仮定した場合，この事象はめったにおこりえないものであるかどうかを見る手法だと言えます。


```{r}


binom.test(x = 40, n = 100, p = 0.5)  
#この場合の比較対象はいかさまのないコインの確率分布なので，p=0.5

#こっちでもおなじこと。

binom.test(x = 60, n = 100, p = 0.5)  


```

この検定結果によれば，5％水準では棄却できませんが10％水準であれば棄却できそうですね。  

なお，この5％とか10％に関係するp値は，得られたデータの正しい確率とは関係のない値です。  
正しい？解釈としては，帰無仮説を棄却（して対立仮説を採択）することが間違っている確率です。



次は文書分類の例を考えてみます。  

例えば，既存の分類器が90％のデータ正しく分類できるものだとして，いま新しく提案した分類手法はさらに精度を改良し，94％のデータを正しく分類できます。ただし，分類した文書の数は1000個だとします。  

果たして新しい分類手法は，従来の手法と比べて変化があるといえるでしょうか。

※本当は，ここで「新しい分類手法の方が優れている」と言いたいのですが，それは片側検定のお仕事になります。まずはここでは両側検定から示します。

```{r}
binom.test(x = 940, n = 1000, p = 0.9) 
```

帰無仮説は棄却できました。次に片側検定を行ってみましょう。この場合の帰無仮説は「新しい分類器は，従来の分類器よりも分類性能が悪い」というものです。

```{r}
binom.test(x = 940, n = 1000, p = 0.9, alternative = "greater" )
```

こちらも棄却できるので，検定結果より「新しい分類器は，従来の分類器よりも性能が悪い」とは言えないということになります。  

なお統計的仮説検定の弱点として，サンプル数が大きいと否応なしに有意な結果が得られやすいということが指摘できます。  

たとえばやはり二項検定の例ですが，
```{r}
pbinom(3,10,0.5)*2
pbinom(300,1000,0.5)*2
```
`pbinom()`関数は二項分布の累積分布を与えてくれる関数です。つまりこれを2倍すれば二項検定（両側検定）のまさにp値が計算されていることになります。
```{r}
binom.test(3,10,0.5)
binom.test(300,1000,0.5)
```

この結果を見てもらえば分かるように，同じ比率でも，10回しかコインを投げなかったときは10％水準でも有意でなかったのに対し，1000回試行した時は有意であるという結果になります（おなじ比率なのに！！）。  

このような性質を利用したり，都合の悪いデータなどを削除して統計的仮説検定をおこなうことをp-hackingなどといいます。
  

  
###  脱線
このとき検定統計量を，データの比率と一致させると，
```{r}
binom.test(x = 940, n = 1000, p = 0.94)
```
なぜかp値が1になってしまいます。  
コイントスの例でも同様の結果です。

```{r}
binom.test(10,20,0.5)
```

p値だけを計算すると，
```{r}
pbinom(10,20,0.5)*2
```
こうなります。  
(でもp値が1以上だなんておかしなはなしですね。)


